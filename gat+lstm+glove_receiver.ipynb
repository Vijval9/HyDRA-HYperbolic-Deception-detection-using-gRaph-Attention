{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11376620,"sourceType":"datasetVersion","datasetId":7122612},{"sourceId":11376656,"sourceType":"datasetVersion","datasetId":7122642},{"sourceId":233104996,"sourceType":"kernelVersion"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom transformers import BertTokenizer\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pack_padded_sequence\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.metrics import f1_score\nimport nltk\nnltk.download('punkt_tab')\n\nfrom tqdm import tqdm\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c43KEZVWTPYQ","outputId":"b6793a8d-127e-415e-e37d-c4404ec28581","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:49.859929Z","iopub.execute_input":"2025-04-12T15:02:49.860297Z","iopub.status.idle":"2025-04-12T15:02:49.866817Z","shell.execute_reply.started":"2025-04-12T15:02:49.860264Z","shell.execute_reply":"2025-04-12T15:02:49.866018Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:49.868344Z","iopub.execute_input":"2025-04-12T15:02:49.868661Z","iopub.status.idle":"2025-04-12T15:02:52.955945Z","shell.execute_reply.started":"2025-04-12T15:02:49.868636Z","shell.execute_reply":"2025-04-12T15:02:52.955017Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uc5Gt5dYUfGt","outputId":"6c9e8c9a-a4fa-4d25-8d0b-5de075ee8c66","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:52.957075Z","iopub.execute_input":"2025-04-12T15:02:52.957384Z","iopub.status.idle":"2025-04-12T15:02:52.961678Z","shell.execute_reply.started":"2025-04-12T15:02:52.957353Z","shell.execute_reply":"2025-04-12T15:02:52.960852Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import random\n\nseed = 100\n\ntorch.manual_seed(seed)\nrandom.seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"id":"xcQyz2yhVv5W","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:52.962639Z","iopub.execute_input":"2025-04-12T15:02:52.962931Z","iopub.status.idle":"2025-04-12T15:02:52.978802Z","shell.execute_reply.started":"2025-04-12T15:02:52.962908Z","shell.execute_reply":"2025-04-12T15:02:52.978251Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"with open(\"/kaggle/input/dataset/2020_acl_diplomacy-master/data/test.jsonl\", \"r\", encoding=\"utf-8\") as file:\n    test_data = [json.loads(line) for line in file]\n\nwith open(\"/kaggle/input/dataset/2020_acl_diplomacy-master/data/train.jsonl\", \"r\", encoding=\"utf-8\") as file:\n    train_data = [json.loads(line) for line in file]\n\nwith open(\"/kaggle/input/dataset/2020_acl_diplomacy-master/data/validation.jsonl\", \"r\", encoding=\"utf-8\") as file:\n    val_data = [json.loads(line) for line in file]\n\n","metadata":{"id":"xdVAb-FnTPYR","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:52.980656Z","iopub.execute_input":"2025-04-12T15:02:52.980833Z","iopub.status.idle":"2025-04-12T15:02:53.184833Z","shell.execute_reply.started":"2025-04-12T15:02:52.980820Z","shell.execute_reply":"2025-04-12T15:02:53.184299Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def preprocess(sentence ):\n    sentence=sentence.lower()\n\n    sentence = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", sentence)  # can use punctations with bert , not with glove\n    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n\n    return sentence\n\ndef prep_data_context(data ,  is_sender ):\n    final_data=[]\n    for data_points in data:\n        sub = []\n        for i, message in enumerate(data_points[\"messages\"]):\n\n            msg=preprocess(message )\n            msg=word_tokenize(msg)\n            if(len(msg)==0): continue\n\n            if(is_sender):\n              if(data_points['sender_labels'][i]=='NOANNOTATION'):\n                continue\n            else:\n              if(data_points['receiver_labels'][i]=='NOANNOTATION'):\n                continue\n\n            sub.append({\"message\":msg ,\n                        \"label\":(data_points[\"receiver_labels\"][i],data_points[\"sender_labels\"][i] )[is_sender] ,\n                        \"game_score_delta\": int(data_points[\"game_score_delta\"][i])})\n        if(len(sub)==0): continue\n        final_data.append(sub)\n    return final_data","metadata":{"id":"8qal_iBqTPYS","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:53.185513Z","iopub.execute_input":"2025-04-12T15:02:53.185693Z","iopub.status.idle":"2025-04-12T15:02:53.191828Z","shell.execute_reply.started":"2025-04-12T15:02:53.185679Z","shell.execute_reply":"2025-04-12T15:02:53.191281Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"val=prep_data_context(val_data, 0)\ntrain=prep_data_context(train_data,0)\ntest=prep_data_context(test_data ,0)","metadata":{"id":"-1sXWsKaTPYS","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:53.192559Z","iopub.execute_input":"2025-04-12T15:02:53.193255Z","iopub.status.idle":"2025-04-12T15:02:54.797145Z","shell.execute_reply.started":"2025-04-12T15:02:53.193235Z","shell.execute_reply":"2025-04-12T15:02:54.796584Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"tokens = []\nfor sub in train:\n  for data_p in sub:\n    for word in data_p[\"message\"]:\n        tokens.append(word)\ntokens=list(set(tokens))\n\nvocab = {token:idx+2  for idx , token in enumerate(tokens)}\nvocab[\"<PAD>\"]=0\nvocab[\"<UNK>\"]=1\n","metadata":{"id":"Wsx9mhKOTPYS","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:54.797800Z","iopub.execute_input":"2025-04-12T15:02:54.797990Z","iopub.status.idle":"2025-04-12T15:02:54.844074Z","shell.execute_reply.started":"2025-04-12T15:02:54.797975Z","shell.execute_reply":"2025-04-12T15:02:54.843523Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\nclass Deception_dataset_context(Dataset):\n    def __init__(self, data , vocab):\n        self.data = data\n        self.vocab= vocab\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n      data_p = self.data[idx]\n      msg_ids = []\n      for sub in data_p:\n          sub_msg_id = []\n          for token in sub['message']:\n              if token in self.vocab:\n                  sub_msg_id.append(self.vocab[token])\n              else:\n                  sub_msg_id.append(self.vocab[\"<UNK>\"])\n          msg_ids.append(torch.tensor(sub_msg_id, dtype=torch.long))\n          # pritn(msg_ids[-1].shape)\n      try:\n          return {\n              \"messages\": msg_ids,\n              \"labels\": torch.tensor([i['label'] for i in data_p], dtype=torch.long),\n              \"game_score_delta\": torch.tensor([i[\"game_score_delta\"] for i in data_p], dtype=torch.float)\n          }\n      except Exception as e:\n          print(\"issue: \", e)\n          return\n\n","metadata":{"id":"XZs0LKaJcRwl","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:54.844734Z","iopub.execute_input":"2025-04-12T15:02:54.844925Z","iopub.status.idle":"2025-04-12T15:02:54.850996Z","shell.execute_reply.started":"2025-04-12T15:02:54.844910Z","shell.execute_reply":"2025-04-12T15:02:54.850346Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def collate_fn_context(batch):\n    messages = []\n    labels = []\n    lengths = []\n    game_score_deltas = []\n    num_messages = []\n    for i in batch:\n      # print(len(i['messages']))\n      # print((i['messages'][0]).shape)\n      messages.extend(i['messages'])\n      lengths.extend([len(j) for j in i['messages']])\n      labels.extend(i['labels'])\n      num_messages.append(len(i['messages']))\n      game_score_deltas.extend(i['game_score_delta'])\n    # print(len(messages))\n    padded_messages = pad_sequence(messages,batch_first=True,padding_value=0)\n\n\n    return {\n        \"messages\": padded_messages,\n        \"lengths\": lengths,\n        \"labels\": torch.tensor(labels),\n        \"num_messages\":num_messages,\n        \"deltas\":torch.tensor(game_score_deltas)\n    }\n","metadata":{"id":"PE2fGpjJetfL","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:54.851748Z","iopub.execute_input":"2025-04-12T15:02:54.852020Z","iopub.status.idle":"2025-04-12T15:02:54.868274Z","shell.execute_reply.started":"2025-04-12T15:02:54.851997Z","shell.execute_reply":"2025-04-12T15:02:54.867622Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def load_glove(file):\n    embeddings = {}\n    with open(file, 'r', encoding='utf-8') as f:\n        for line in f:\n            embed = line.split()\n            word = embed[0]\n            embedding = torch.tensor([float(i) for i in embed[1:]], dtype=torch.float)\n            embeddings[word] = embedding\n    return embeddings","metadata":{"id":"euYr7GTFTPYT","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:02:54.868948Z","iopub.execute_input":"2025-04-12T15:02:54.869196Z","iopub.status.idle":"2025-04-12T15:02:54.882001Z","shell.execute_reply.started":"2025-04-12T15:02:54.869181Z","shell.execute_reply":"2025-04-12T15:02:54.881456Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import random\nimport torch_geometric\nfrom torch_geometric.data import Batch, Data\n\nclass ContextLSTM(nn.Module):\n  def __init__(self,vocab, glove_file, embedding_dim, hidden_size_message, gat_dim, num_classes):\n    super(ContextLSTM,self).__init__()\n    seed = 100\n    torch.manual_seed(seed)\n    random.seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    glove_embeddings = load_glove(glove_file)\n\n    vocab_size = len(vocab)\n    self.embedding_matrix = torch.zeros(vocab_size, embedding_dim)\n    for token, idx in vocab.items():\n        if token in glove_embeddings:\n            self.embedding_matrix[idx] = glove_embeddings[token]\n        else:\n            self.embedding_matrix[idx] = torch.randn(embedding_dim) * 0.6\n\n    self.embedding = nn.Embedding.from_pretrained(self.embedding_matrix, freeze=True, padding_idx=0)\n\n    self.lstm_message = nn.LSTM(embedding_dim, hidden_size_message, batch_first=True, bidirectional=True)\n    # self.gat1 = torch_geometric.nn.conv.GATConv(in_channels=hidden_size_message*2,out_channels=gat_dim//2,heads=4)\n    self.gat1 = torch_geometric.nn.conv.GATConv(in_channels=hidden_size_message*2,out_channels=gat_dim*2,heads=4,  concat=False)\n      \n    self.gat2 = torch_geometric.nn.conv.GATConv(in_channels=gat_dim*2,out_channels=gat_dim,heads=2 , concat=False)\n    self.fc = nn.Linear(hidden_size_message * 2 + gat_dim, num_classes)\n    self.relu = torch.nn.ReLU()\n    self.tanh = torch.nn.Tanh()\n    self.sigmoid = torch.nn.Sigmoid()  \n    self.gate1 = nn.Linear(hidden_size_message * 2 + gat_dim,hidden_size_message * 2)\n    self.gate2 = nn.Linear(hidden_size_message * 2 + gat_dim,gat_dim)\n    self.hidden_size_message = hidden_size_message\n    self.gat_dim = gat_dim\n\n  def fusion(self,x):\n      lstm_emb = x[:,:2*self.hidden_size_message]\n      gat_emb = x[:,2*self.hidden_size_message:]\n      \n      lstm_emb_tanh = self.tanh(lstm_emb) \n      gat_emb_tanh = self.tanh(gat_emb)\n      # print('lstm emb: ',lstm_emb.shape)\n      # print(\"gat emb shape: \",gat_emb.shape)\n      mixed = torch.cat((lstm_emb,gat_emb),dim=1)\n      mixed_sigmoid_left = self.sigmoid(self.gate1(mixed))\n      mixed_sigmoid_right = self.sigmoid(self.gate2(mixed))\n\n      final_emb = torch.cat((mixed_sigmoid_left*lstm_emb_tanh,mixed_sigmoid_right*gat_emb_tanh),dim=1)\n      return final_emb\n\n  def get_message_emb(self,input_ids,lengths):\n    embedded = self.embedding(input_ids)\n    # print(embedded.shape)\n    packed = pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n\n    _, (hn, _1) = self.lstm_message(packed)\n    last_hidden = torch.cat((hn[0], hn[1]), dim=1)\n    return last_hidden\n\n  \n\n  def forward(self, input_ids, num_messages, lengths , scores):\n    total_messages = sum(num_messages)\n    inputs_to_msg_encoder = input_ids\n    encoded_messages = self.get_message_emb(inputs_to_msg_encoder,lengths)\n    input_to_convo_encoder = torch.split(encoded_messages,num_messages)\n    # print(input_to_convo_encoder[0].shape)\n\n    tot_data = []\n\n    for i in range(len(input_to_convo_encoder)):\n        msg_embs = input_to_convo_encoder[i] # num_msgs x emb_dim\n        n_nodes = msg_embs.shape[0]\n        edge_ind = torch.combinations(torch.arange(n_nodes), r=2).T\n        edge_ind = torch.cat([edge_ind, edge_ind.flip(0)], dim=1).to(input_ids.device)\n    \n        tot_data.append(Data(x=msg_embs,edge_index=edge_ind))\n\n    tot_data = Batch.from_data_list(tot_data)\n    from_gat1 = self.relu(self.gat1(tot_data.x,tot_data.edge_index))\n    \n    # print(\"from gat 1 shape: \",from_gat1.shape)\n\n    from_gat2 = self.gat2(from_gat1,tot_data.edge_index)\n    # print(\"enc msg shape: \",encoded_messages.shape)\n    # print(\"from_gat2 shap: \",from_gat2.shape)\n      \n    input_for_fusion = [] \n    prev = 0\n    # print(\"enc msg shape: \",encoded_messages.shape)\n    for i, msg_emb in enumerate(encoded_messages):\n        # print(\"i: \",i)\n        inp = torch.cat((msg_emb,from_gat2[i]),dim=0)\n        input_for_fusion.append(inp)\n    # print(\"shape before fusion: \",torch.stack(input_for_fusion).shape)\n    final_combined = self.fusion(torch.stack(input_for_fusion))\n    # print(\"final combined shape: \",final_combined.shape)\n    final_input = torch.cat((final_combined,  scores.unsqueeze(1)), dim=1)\n    # print(final_input.shape)\n    logits = self.fc(final_combined)\n    # print(\"logits shape: \",logits.shape)\n    return logits\n\n","metadata":{"id":"hG6f4m63ND-N","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:37:51.889721Z","iopub.execute_input":"2025-04-12T15:37:51.890067Z","iopub.status.idle":"2025-04-12T15:37:51.904357Z","shell.execute_reply.started":"2025-04-12T15:37:51.890047Z","shell.execute_reply":"2025-04-12T15:37:51.903786Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"Train Context LSTM:","metadata":{"id":"HW04PFmPgQoD"}},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nglove_file = \"/kaggle/input/gloveembed/glove.6B.100d.txt\"\nembedding_dim = 100\nhidden_size = 100\nnum_classes = 2\ngat_dim = 50\n\nseed = 100\n\ntorch.manual_seed(seed)\nrandom.seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nmodel = ContextLSTM(vocab, glove_file, embedding_dim, hidden_size,gat_dim, num_classes)\nmodel = model.to(device)\n\nclass_weights = torch.tensor([1.0 / 0.10, 1.0 / 0.90], dtype=torch.float)\nclass_weights = class_weights.to(device)\n\n\n# model = ContextLSTM(vocab, glove_file, embedding_dim, hidden_size//2,hidden_size, num_classes)\n# model = model.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.003)\nloss = nn.CrossEntropyLoss(weight=class_weights)\n\ntrain_dataset = Deception_dataset_context(train, vocab)\nval_dataset = Deception_dataset_context(val, vocab)\ntrain_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn_context)\nval_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn_context)\n\n\ntest_dataset = Deception_dataset_context(test, vocab)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_context)\n\nprint(\"hey\")\nfor epoch in range(16):\n    \n    model.train()\n    train_loss = 0\n    train_preds, train_labels = [], []\n    for batch in tqdm(train_dataloader):\n        messages = batch[\"messages\"].to(device)\n        lengths = batch[\"lengths\"]\n        labels = batch[\"labels\"].to(device)\n        num_messages = batch['num_messages']\n        scores = batch['deltas'].to(device)\n\n        optimizer.zero_grad()\n        logits = model(messages, num_messages,lengths,scores)\n        loss_ = loss(logits, labels)\n        loss_.backward()\n        optimizer.step()\n\n        train_loss += loss_.item()\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        train_preds.extend(preds)\n        train_labels.extend(labels.cpu().numpy())\n\n\n    train_loss /= len(train_dataloader)\n    train_f1 = f1_score(train_labels, train_preds, average='macro')\n\n\n    model.eval()\n    val_loss = 0\n    val_preds, val_labels = [], []\n    with torch.no_grad():\n        for batch in val_dataloader:\n            messages = batch[\"messages\"].to(device)\n            lengths = batch[\"lengths\"]\n            labels = batch[\"labels\"].to(device)\n            num_messages = batch['num_messages']\n            scores = batch['deltas'].to(device)\n            logits = model(messages, num_messages,lengths,scores)\n            loss_ = loss(logits, labels)\n            val_loss += loss_.item()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            val_preds.extend(preds)\n            val_labels.extend(labels.cpu().numpy())\n\n    val_loss /= len(val_dataloader)\n    val_f1 = f1_score(val_labels, val_preds, average='macro')\n\n    model.eval()\n    test_preds, test_labels = [], []\n    with torch.no_grad():\n        for batch in test_dataloader:\n            messages = batch[\"messages\"].to(device)\n            lengths = batch[\"lengths\"]\n            labels = batch[\"labels\"].to(device)\n            num_messages = batch['num_messages']\n            scores = batch['deltas'].to(device)\n            logits = model(messages, num_messages,lengths,scores)\n    \n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            test_preds.extend(preds)\n            test_labels.extend(labels.cpu().numpy())\n    \n    \n    test_f1 = f1_score(test_labels, test_preds, average='macro')\n    \n    print(test_f1)\n\n\n    print(f\"Epoch {epoch+1}:  Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f} Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M7eDWYJtgSpg","outputId":"bac03c34-5da2-4c9e-fb8c-da347295e309","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:39:42.558640Z","iopub.execute_input":"2025-04-12T15:39:42.558911Z","iopub.status.idle":"2025-04-12T15:40:28.409075Z","shell.execute_reply.started":"2025-04-12T15:39:42.558894Z","shell.execute_reply":"2025-04-12T15:40:28.408274Z"}},"outputs":[{"name":"stdout","text":"hey\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4824690321226118\nEpoch 1:  Train Loss: 0.6508, Train F1: 0.4873 Val Loss: 0.6437, Val F1: 0.4906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4826862539349423\nEpoch 2:  Train Loss: 0.6250, Train F1: 0.4897 Val Loss: 0.6309, Val F1: 0.4906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4824690321226118\nEpoch 3:  Train Loss: 0.6261, Train F1: 0.4879 Val Loss: 0.6310, Val F1: 0.4906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4824690321226118\nEpoch 4:  Train Loss: 0.6335, Train F1: 0.4894 Val Loss: 0.6339, Val F1: 0.4906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4824690321226118\nEpoch 5:  Train Loss: 0.6066, Train F1: 0.4877 Val Loss: 0.6401, Val F1: 0.4906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4824690321226118\nEpoch 6:  Train Loss: 0.6167, Train F1: 0.4877 Val Loss: 0.6351, Val F1: 0.4906\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4824690321226118\nEpoch 7:  Train Loss: 0.6188, Train F1: 0.4912 Val Loss: 0.6390, Val F1: 0.4904\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4818162707588816\nEpoch 8:  Train Loss: 0.6043, Train F1: 0.5031 Val Loss: 0.6564, Val F1: 0.4890\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.489213691026827\nEpoch 9:  Train Loss: 0.5940, Train F1: 0.5148 Val Loss: 0.6427, Val F1: 0.4964\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.49724859430363044\nEpoch 10:  Train Loss: 0.5949, Train F1: 0.5316 Val Loss: 0.6394, Val F1: 0.4975\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.502075221332762\nEpoch 11:  Train Loss: 0.5783, Train F1: 0.5492 Val Loss: 0.6688, Val F1: 0.4888\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.5120532980322534\nEpoch 12:  Train Loss: 0.5623, Train F1: 0.5637 Val Loss: 0.6750, Val F1: 0.4939\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.5093535616065762\nEpoch 13:  Train Loss: 0.5171, Train F1: 0.5779 Val Loss: 0.7949, Val F1: 0.5032\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.5408900603168308\nEpoch 14:  Train Loss: 0.5187, Train F1: 0.5909 Val Loss: 0.6650, Val F1: 0.4860\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.5241594448719896\nEpoch 15:  Train Loss: 0.4682, Train F1: 0.6151 Val Loss: 0.8264, Val F1: 0.5229\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 12/12 [00:01<00:00,  6.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.5456896551724137\nEpoch 16:  Train Loss: 0.4312, Train F1: 0.6416 Val Loss: 0.8424, Val F1: 0.5037\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":" torch.save(model.state_dict(),f\"gat+lstm+glove_best.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:42:20.415834Z","iopub.execute_input":"2025-04-12T15:42:20.416120Z","iopub.status.idle":"2025-04-12T15:42:20.430697Z","shell.execute_reply.started":"2025-04-12T15:42:20.416101Z","shell.execute_reply":"2025-04-12T15:42:20.429919Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"test_dataset = Deception_dataset_context(test, vocab)\ntest_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_context)\n\n\nmodel.eval()\ntest_preds, test_labels = [], []\nwith torch.no_grad():\n    for batch in test_dataloader:\n        messages = batch[\"messages\"].to(device)\n        lengths = batch[\"lengths\"]\n        labels = batch[\"labels\"].to(device)\n        num_messages = batch['num_messages']\n        scores = batch['deltas'].to(device)\n        logits = model(messages, num_messages,lengths,scores)\n\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        test_preds.extend(preds)\n        test_labels.extend(labels.cpu().numpy())\n\n\ntest_f1 = f1_score(test_labels, test_preds, average='macro')\n\nprint(test_f1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzlomltYh7zj","outputId":"6e04ba6a-66f7-4bad-edd5-d0f72f7e33fb","trusted":true,"execution":{"iopub.status.busy":"2025-04-12T15:40:46.427513Z","iopub.execute_input":"2025-04-12T15:40:46.427775Z","iopub.status.idle":"2025-04-12T15:40:46.612808Z","shell.execute_reply.started":"2025-04-12T15:40:46.427757Z","shell.execute_reply":"2025-04-12T15:40:46.612213Z"}},"outputs":[{"name":"stdout","text":"0.5456896551724137\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"","metadata":{"id":"vbqfSpqHa4fa","trusted":true},"outputs":[],"execution_count":null}]}
