{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11352765,"sourceType":"datasetVersion","datasetId":7104149},{"sourceId":11352813,"sourceType":"datasetVersion","datasetId":7104195},{"sourceId":11376620,"sourceType":"datasetVersion","datasetId":7122612},{"sourceId":11376656,"sourceType":"datasetVersion","datasetId":7122642},{"sourceId":11385451,"sourceType":"datasetVersion","datasetId":7129308},{"sourceId":11385465,"sourceType":"datasetVersion","datasetId":7129315},{"sourceId":11389469,"sourceType":"datasetVersion","datasetId":7132411}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":18726.947518,"end_time":"2025-04-14T09:21:48.168875","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-14T04:09:41.221357","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"02b780034974497092794cdcfaf336ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_9d513090ef3f4c189b3a6dd18950fc51","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b1cc257b14d440f9f4cdeda9ed26f09","tabbable":null,"tooltip":null,"value":570}},"10284b29b78c4015abfc90beac197779":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bacc9bc962e4e6b8bac83e3f0df1635":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36fa21ae10db4882a51474eb19944c53","IPY_MODEL_f814f4d1b832486ebe11ff41a4c5ebd6","IPY_MODEL_232856e154644e43a9eaa31aadf43025"],"layout":"IPY_MODEL_f83e429ef71d4c30bdd3f07a849cbc81","tabbable":null,"tooltip":null}},"232856e154644e43a9eaa31aadf43025":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f1b6a010a02843878509f2deb688f2a3","placeholder":"​","style":"IPY_MODEL_766728ad4ad544bfbd1b41a4296a33e4","tabbable":null,"tooltip":null,"value":" 48.0/48.0 [00:00&lt;00:00, 5.19kB/s]"}},"2c5006bc7ecf4b8ebe0c5ee57e3022e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"30f98b78e659493a85c68b0243d45612":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35a227ce812544c88c34cfc1ae91383d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"36fa21ae10db4882a51474eb19944c53":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_10284b29b78c4015abfc90beac197779","placeholder":"​","style":"IPY_MODEL_449f73b35d4d48b480591dbff0161b27","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"3cfb7d983d224b73a41a212819b64096":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"402a4329cdfb42df8556f2cbe856a8a0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"422434686ee04405887e743a8cc4c24e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"449f73b35d4d48b480591dbff0161b27":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"46465d3a01ac4a8990ff5a4b1fa238ce":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"528edd69324740b79f40ed974496b44d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_b362fd0cd74f4aaaada7896e3213c7f5","placeholder":"​","style":"IPY_MODEL_2c5006bc7ecf4b8ebe0c5ee57e3022e1","tabbable":null,"tooltip":null,"value":"tokenizer.json: 100%"}},"54e6dd06a21f4f239cf960508062cbc2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d350b5f14e48949820294047d69c4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"675fca8ef2dd4f58a695e00eacb25997":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_528edd69324740b79f40ed974496b44d","IPY_MODEL_b4449322495b4171bb8785bcb5777fd2","IPY_MODEL_f18d3794580e4b939dcd47a150bb4fe5"],"layout":"IPY_MODEL_dcce6d05d3754c2caa2c1b4acc1a0410","tabbable":null,"tooltip":null}},"6b1cc257b14d440f9f4cdeda9ed26f09":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"766728ad4ad544bfbd1b41a4296a33e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"7d794bdb33614f09998e079ed7cbfc8b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"910d0af55dbd43b3bd19b4e6ba0098e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9251b710a1cc467bb3e431e1f16f7e46":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_46465d3a01ac4a8990ff5a4b1fa238ce","placeholder":"​","style":"IPY_MODEL_995d2678a3664d549a474605add70602","tabbable":null,"tooltip":null,"value":" 232k/232k [00:00&lt;00:00, 12.8MB/s]"}},"92f90cb97ee24336b336bd9b90eb8378":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"964905fc0abb4853893eb05cdbbdf670":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_9c924ddb4dd44007862536ec9303ee09","placeholder":"​","style":"IPY_MODEL_c6f2da7d229c4c6791521ce42e6a05ba","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"995d2678a3664d549a474605add70602":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"9c924ddb4dd44007862536ec9303ee09":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d513090ef3f4c189b3a6dd18950fc51":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a84e28a460b04af79e99573d41dd83c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a97e675d4a914b269fb965a059b31f50":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_54e6dd06a21f4f239cf960508062cbc2","placeholder":"​","style":"IPY_MODEL_61d350b5f14e48949820294047d69c4e","tabbable":null,"tooltip":null,"value":"vocab.txt: 100%"}},"aa0145af490b41548c509db112bddd62":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_da81e805919241f887d430499aa725e8","placeholder":"​","style":"IPY_MODEL_d71c2675004f4671b144232ddf1f7d6c","tabbable":null,"tooltip":null,"value":" 570/570 [00:00&lt;00:00, 70.4kB/s]"}},"adf6d0df7478439ca3b3d83fa09cff51":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a97e675d4a914b269fb965a059b31f50","IPY_MODEL_c28c08f61e514fb0b8ab922ea8f3ce71","IPY_MODEL_9251b710a1cc467bb3e431e1f16f7e46"],"layout":"IPY_MODEL_7d794bdb33614f09998e079ed7cbfc8b","tabbable":null,"tooltip":null}},"b362fd0cd74f4aaaada7896e3213c7f5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b42263eeea3942ef9d76bfdd2b21b00f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d15ae6f774c8405aa639b6f8b39f51ee","IPY_MODEL_02b780034974497092794cdcfaf336ad","IPY_MODEL_aa0145af490b41548c509db112bddd62"],"layout":"IPY_MODEL_402a4329cdfb42df8556f2cbe856a8a0","tabbable":null,"tooltip":null}},"b4449322495b4171bb8785bcb5777fd2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_422434686ee04405887e743a8cc4c24e","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30f98b78e659493a85c68b0243d45612","tabbable":null,"tooltip":null,"value":466062}},"ba8ec9aed3a74af291c4a97738fe885f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_964905fc0abb4853893eb05cdbbdf670","IPY_MODEL_ce92c47401a34e4992c57a46d0a1ab2e","IPY_MODEL_dc567013e5eb46ddbcb0de1464935df1"],"layout":"IPY_MODEL_caa7bcf8396547c0829d750aaa8a9575","tabbable":null,"tooltip":null}},"c28c08f61e514fb0b8ab922ea8f3ce71":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_d99181c34a5f4cd3882d4eae8fd702fd","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_910d0af55dbd43b3bd19b4e6ba0098e5","tabbable":null,"tooltip":null,"value":231508}},"c6f2da7d229c4c6791521ce42e6a05ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"caa7bcf8396547c0829d750aaa8a9575":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce92c47401a34e4992c57a46d0a1ab2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_92f90cb97ee24336b336bd9b90eb8378","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f919e26732a34a148fccefc308f27390","tabbable":null,"tooltip":null,"value":440449768}},"d0af902238e04e7c831496115fa3b78c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d15ae6f774c8405aa639b6f8b39f51ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_db5362d26b0840c094a25c01c51d7a23","placeholder":"​","style":"IPY_MODEL_dfcba5ff08434bdbb07df64fc1b6711c","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"d71c2675004f4671b144232ddf1f7d6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d99181c34a5f4cd3882d4eae8fd702fd":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da81e805919241f887d430499aa725e8":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db5362d26b0840c094a25c01c51d7a23":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc567013e5eb46ddbcb0de1464935df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d0af902238e04e7c831496115fa3b78c","placeholder":"​","style":"IPY_MODEL_a84e28a460b04af79e99573d41dd83c6","tabbable":null,"tooltip":null,"value":" 440M/440M [00:01&lt;00:00, 395MB/s]"}},"dcce6d05d3754c2caa2c1b4acc1a0410":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfcba5ff08434bdbb07df64fc1b6711c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"ebe67b10335448c3926d405f4d4585c5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f18d3794580e4b939dcd47a150bb4fe5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3cfb7d983d224b73a41a212819b64096","placeholder":"​","style":"IPY_MODEL_35a227ce812544c88c34cfc1ae91383d","tabbable":null,"tooltip":null,"value":" 466k/466k [00:00&lt;00:00, 2.82MB/s]"}},"f1b6a010a02843878509f2deb688f2a3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f77c30993ff34835a7c8e91008ab00e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f814f4d1b832486ebe11ff41a4c5ebd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_ebe67b10335448c3926d405f4d4585c5","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f77c30993ff34835a7c8e91008ab00e7","tabbable":null,"tooltip":null,"value":48}},"f83e429ef71d4c30bdd3f07a849cbc81":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f919e26732a34a148fccefc308f27390":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5e1c15dc","cell_type":"code","source":"import json\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom transformers import BertTokenizer\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pack_padded_sequence\nfrom torch.nn.utils.rnn import pad_sequence\nfrom sklearn.metrics import f1_score\nimport nltk\nnltk.download('punkt_tab')\n\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:48:46.783850Z","iopub.execute_input":"2025-04-14T18:48:46.784203Z","iopub.status.idle":"2025-04-14T18:48:51.928037Z","shell.execute_reply.started":"2025-04-14T18:48:46.784172Z","shell.execute_reply":"2025-04-14T18:48:51.927225Z"},"id":"c43KEZVWTPYQ","outputId":"b6793a8d-127e-415e-e37d-c4404ec28581","papermill":{"duration":9.387903,"end_time":"2025-04-14T04:09:55.129703","exception":false,"start_time":"2025-04-14T04:09:45.741800","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n","output_type":"stream"}],"execution_count":1},{"id":"ca22b465","cell_type":"code","source":"!pip install torch_geometric","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:48:51.929440Z","iopub.execute_input":"2025-04-14T18:48:51.929800Z","iopub.status.idle":"2025-04-14T18:48:56.682364Z","shell.execute_reply.started":"2025-04-14T18:48:51.929781Z","shell.execute_reply":"2025-04-14T18:48:56.681666Z"},"papermill":{"duration":5.118881,"end_time":"2025-04-14T04:10:00.252257","exception":false,"start_time":"2025-04-14T04:09:55.133376","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.19.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":2},{"id":"447a77c1","cell_type":"code","source":"import random\n\nseed = 100\n\ntorch.manual_seed(seed)\nrandom.seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:48:56.683311Z","iopub.execute_input":"2025-04-14T18:48:56.683522Z","iopub.status.idle":"2025-04-14T18:48:56.692780Z","shell.execute_reply.started":"2025-04-14T18:48:56.683502Z","shell.execute_reply":"2025-04-14T18:48:56.692158Z"},"id":"xcQyz2yhVv5W","papermill":{"duration":0.016041,"end_time":"2025-04-14T04:10:00.272702","exception":false,"start_time":"2025-04-14T04:10:00.256661","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"06f8a794","cell_type":"code","source":"with open(\"/kaggle/input/diplomacy/2020_acl_diplomacy-master/data/test.jsonl\", \"r\", encoding=\"utf-8\") as file:\n    test_data = [json.loads(line) for line in file]\n\nwith open(\"/kaggle/input/diplomacy/2020_acl_diplomacy-master/data/train.jsonl\", \"r\", encoding=\"utf-8\") as file:\n    train_data = [json.loads(line) for line in file]\n\nwith open(\"/kaggle/input/diplomacy/2020_acl_diplomacy-master/data/validation.jsonl\", \"r\", encoding=\"utf-8\") as file:\n    val_data = [json.loads(line) for line in file]\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:50:33.782504Z","iopub.execute_input":"2025-04-14T18:50:33.782808Z","iopub.status.idle":"2025-04-14T18:50:33.914614Z","shell.execute_reply.started":"2025-04-14T18:50:33.782787Z","shell.execute_reply":"2025-04-14T18:50:33.914060Z"},"id":"xdVAb-FnTPYR","papermill":{"duration":0.264064,"end_time":"2025-04-14T04:10:00.543092","exception":false,"start_time":"2025-04-14T04:10:00.279028","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"d43fcfb2","cell_type":"code","source":"import re\n\ndef preprocess(sentence):\n    sentence = sentence.lower()\n    sentence = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", sentence)  # remove punctuation (Glove)\n    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n    return sentence\n\ndef prep_data_context(data, is_sender, is_train, tokenizer):\n    final_data = []\n    chunk_size = 230\n\n    for data_points in data:\n        messages = data_points[\"messages\"]\n        labels = data_points[\"sender_labels\"] if is_sender else data_points[\"receiver_labels\"]\n        game_score_deltas = data_points[\"game_score_delta\"]\n\n        # For training, split into 300-message chunks\n        chunks = (\n            [messages[i:i+chunk_size] for i in range(0, len(messages), chunk_size)]\n            if is_train else [messages]\n        )\n\n        for chunk_index, message_chunk in enumerate(chunks):\n            sub = []\n            for i, message in enumerate(message_chunk):\n                index = i + chunk_index * chunk_size\n                if index >= len(labels) or labels[index] == 'NOANNOTATION':\n                    continue\n\n                msg = preprocess(message)\n                tokenized = tokenizer(msg, truncation=True,max_length=200)\n\n                if len(tokenized[\"input_ids\"]) == 0:\n                    continue\n\n                sub.append({\n                    \"message\": tokenized[\"input_ids\"],\n                    \"label\": labels[index],\n                    \"game_score_delta\": int(game_score_deltas[index])\n                })\n\n            if sub:\n                final_data.append(sub)\n\n    return final_data\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:50:35.732745Z","iopub.execute_input":"2025-04-14T18:50:35.733407Z","iopub.status.idle":"2025-04-14T18:50:35.740675Z","shell.execute_reply.started":"2025-04-14T18:50:35.733384Z","shell.execute_reply":"2025-04-14T18:50:35.739847Z"},"id":"8qal_iBqTPYS","papermill":{"duration":0.012502,"end_time":"2025-04-14T04:10:00.559487","exception":false,"start_time":"2025-04-14T04:10:00.546985","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":6},{"id":"3b9a4f5e","cell_type":"code","source":"from transformers import BertTokenizerFast\ntokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\nval=prep_data_context(val_data,1,False,tokenizer)\ntrain=prep_data_context(train_data,1,True,tokenizer)\ntest=prep_data_context(test_data,1,False,tokenizer)","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:50:38.683602Z","iopub.execute_input":"2025-04-14T18:50:38.684287Z","iopub.status.idle":"2025-04-14T18:50:43.561027Z","shell.execute_reply.started":"2025-04-14T18:50:38.684256Z","shell.execute_reply":"2025-04-14T18:50:43.560374Z"},"id":"-1sXWsKaTPYS","papermill":{"duration":4.7541,"end_time":"2025-04-14T04:10:05.316974","exception":false,"start_time":"2025-04-14T04:10:00.562874","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa2269a763134a4f8db7f2c49d6daa6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38fe061f69af46bcba67ea01e70fe10b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45a38f63b9d346e08ccafceb7d55b8ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62107340d4f34000b208c8b8da1259ad"}},"metadata":{}}],"execution_count":7},{"id":"ac6f010e","cell_type":"code","source":"tokens = []\nfor sub in train:\n  for data_p in sub:\n    for word in data_p[\"message\"]:\n        tokens.append(word)\ntokens=list(set(tokens))\n\nvocab = {token:idx+2  for idx , token in enumerate(tokens)}\nvocab[\"<PAD>\"]=0\nvocab[\"<UNK>\"]=1\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:50:43.562062Z","iopub.execute_input":"2025-04-14T18:50:43.562482Z","iopub.status.idle":"2025-04-14T18:50:43.603053Z","shell.execute_reply.started":"2025-04-14T18:50:43.562449Z","shell.execute_reply":"2025-04-14T18:50:43.602373Z"},"id":"Wsx9mhKOTPYS","papermill":{"duration":0.04744,"end_time":"2025-04-14T04:10:05.369931","exception":false,"start_time":"2025-04-14T04:10:05.322491","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"aa2c71f8","cell_type":"code","source":"\nclass Deception_dataset_context(Dataset):\n    def __init__(self, data ):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n      data_p = self.data[idx]\n      msg_ids = []\n      \n      for sub in data_p:\n        \n          \n          msg_ids.append(torch.tensor(sub[\"message\"], dtype=torch.long))\n    \n          # pritn(msg_ids[-1].shape)\n      try:\n          return {\n              \"messages\": msg_ids,\n              \"labels\": torch.tensor([i['label'] for i in data_p], dtype=torch.long),\n              \"game_score_delta\": torch.tensor([i[\"game_score_delta\"] for i in data_p], dtype=torch.float)\n          }\n      except Exception as e:\n          print(\"issue: \", e)\n          return\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:50:44.342180Z","iopub.execute_input":"2025-04-14T18:50:44.342867Z","iopub.status.idle":"2025-04-14T18:50:44.347965Z","shell.execute_reply.started":"2025-04-14T18:50:44.342845Z","shell.execute_reply":"2025-04-14T18:50:44.347191Z"},"id":"XZs0LKaJcRwl","papermill":{"duration":0.011088,"end_time":"2025-04-14T04:10:05.385206","exception":false,"start_time":"2025-04-14T04:10:05.374118","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"cef6cafe","cell_type":"code","source":"def collate_fn_context(batch):\n    messages = []\n    labels = []\n    lengths = []\n    game_score_deltas = []\n    num_messages = []\n  \n    for i in batch:\n      # print(len(i['messages']))\n      # print((i['messages'][0]).shape)\n      messages.extend(i['messages'])\n  \n      lengths.extend([len(j) for j in i['messages']])\n      labels.extend(i['labels'])\n      num_messages.append(len(i['messages']))\n      game_score_deltas.extend(i['game_score_delta'])\n    # print(len(messages))\n    padded_messages = pad_sequence(messages,batch_first=True,padding_value=0)\n\n\n    return {\n        \"messages\": (padded_messages),\n        \"lengths\": torch.tensor(lengths, dtype=torch.long),\n        \"labels\": torch.tensor(labels),\n        \"num_messages\":num_messages,\n        \"deltas\":torch.tensor(game_score_deltas)\n    }\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:50:48.026019Z","iopub.execute_input":"2025-04-14T18:50:48.026258Z","iopub.status.idle":"2025-04-14T18:50:48.031311Z","shell.execute_reply.started":"2025-04-14T18:50:48.026243Z","shell.execute_reply":"2025-04-14T18:50:48.030695Z"},"id":"PE2fGpjJetfL","papermill":{"duration":0.010031,"end_time":"2025-04-14T04:10:05.399023","exception":false,"start_time":"2025-04-14T04:10:05.388992","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"id":"2cda26ba","cell_type":"code","source":"import torch\nimport torch.nn as nn\n%pip install git+https://github.com/geoopt/geoopt.git\nimport geoopt\n\nclass HyperbolicGRUCell(nn.Module):\n    def __init__(self,inp_dim,hidden_size,manifold):\n        super().__init__()\n        self.inp_dim = inp_dim\n        self.hid_dim = hidden_size\n        self.manifold = manifold\n\n        self.wz = nn.Parameter(nn.init.xavier_normal_(torch.empty(self.hid_dim,self.hid_dim+self.inp_dim,dtype=torch.float64)))\n        self.wr = nn.Parameter(nn.init.xavier_normal_(torch.empty(self.hid_dim,self.hid_dim+self.inp_dim,dtype=torch.float64)))\n        self.w = nn.Parameter(nn.init.xavier_normal_(torch.empty(self.hid_dim,self.hid_dim+self.inp_dim,dtype=torch.float64)))\n\n    def forward(self,h,x):\n        # h and x are of shape bs x hid_dim, bs x inp_dim\n        # this is just one pass, not for a sequence\n        # print(\"h shape: \",h.shape)\n        # print(\"x shape: \",x.shape)\n        h_x = torch.cat((h,x),dim=-1)\n        z = torch.sigmoid(self.manifold.logmap0(self.manifold.projx(self.manifold.mobius_matvec(self.wz,h_x))))\n        r = torch.sigmoid(self.manifold.logmap0(self.manifold.projx(self.manifold.mobius_matvec(self.wr,h_x))))\n        h_x_to_tilde = self.manifold.projx(self.manifold.expmap0(torch.cat((self.manifold.logmap0(self.manifold.mobius_pointwise_mul(r,h)),self.manifold.logmap0(x)),dim=-1)))\n        h_tilde = self.manifold.expmap0(torch.tanh(self.manifold.logmap0(self.manifold.projx(self.manifold.mobius_matvec(self.w,h_x_to_tilde)))))\n        h = self.manifold.projx(self.manifold.mobius_add(self.manifold.mobius_pointwise_mul(1-z,h),self.manifold.mobius_pointwise_mul(z,h_tilde)))\n        return h\n\n\n\nclass HyperbolicGRULayer(nn.Module):\n    def __init__(self,inp_dim,hidden_size,manifold,dirs):\n        super().__init__()\n        self.inp_dim = inp_dim\n        self.hid_dim = hidden_size\n        self.manifold = manifold\n        self.dirs = dirs\n        self.gru_cell = HyperbolicGRUCell(self.inp_dim,self.hid_dim,self.manifold)\n        self.h_init = geoopt.tensor.ManifoldParameter(self.manifold.projx(self.manifold.expmap0(torch.zeros(self.hid_dim,dtype=torch.float64))),manifold=self.manifold)\n\n    def forward(self,seq,lengths):\n        # seq is bs x max_seq_len x inp_dim\n        # h_init is bs x inp_dim\n        # lengths is bs\n        max_len = seq.shape[1]\n        bs = seq.shape[0]\n        hid = self.h_init.expand(bs,-1)\n        outs_left = []\n\n        # left to right\n        for i in range(max_len):\n            inp = seq[:,i,:]\n            out = self.gru_cell(hid,inp) # bs x hid_dim\n            # but not all outputs will be valid. since some sequences may be padded. so i need to ignore those somehow\n            # mask = torch.tensor([1 if len>i else 0 for len in lengths]).unsqueeze(-1).to(seq.device) # error if i dont unsqueeze. inefficient\n            mask = (lengths>i).float().unsqueeze(-1).to(seq.device)\n            hid = self.manifold.projx(self.manifold.mobius_add(self.manifold.mobius_pointwise_mul(mask,out),self.manifold.mobius_pointwise_mul(1-mask,hid)))\n            outs_left.append(hid)\n\n        if(self.dirs==2):\n            hid = self.h_init.expand(bs, -1)\n            seq = torch.flip(seq,dims=[1])\n            outs_right = []\n            # right to left\n            for i in range(max_len):\n                inp = seq[:,i,:]\n                out = self.gru_cell(hid,inp) # bs x hid_dim\n                # but not all outputs will be valid. since some sequences may be padded. so i need to ignore those somehow\n                # mask = torch.tensor([1 if len>i else 0 for len in lengths]).unsqueeze(-1).to(seq.device) # error if i dont unsqueeze. inefficient\n                mask = (lengths>i).float().unsqueeze(-1).to(seq.device)\n                hid = self.manifold.projx(self.manifold.mobius_add(self.manifold.mobius_pointwise_mul(mask,out),self.manifold.mobius_pointwise_mul(1-mask,hid)))\n                outs_right.append(hid)\n\n        outs = torch.stack(outs_left,dim=1)\n        if(self.dirs==2):\n            outs_right.reverse()\n            outs_right = torch.stack(outs_right,dim=1)\n            outs = self.manifold.projx(self.manifold.expmap0(torch.cat((self.manifold.logmap0(outs),self.manifold.logmap0(outs_right)),dim=-1)))\n\n        return outs, outs[:,-1,:]\n\nclass HyperbolicGRU(nn.Module):\n    def __init__(self,inp_dim,hidden_size,manifold,num_layers,dirs):\n        super().__init__()\n        self.inp_dim = inp_dim\n        self.hid_dim = hidden_size\n        self.manifold = manifold\n        self.num_layers = num_layers\n        self.dirs = dirs\n        self.layers = nn.ModuleList()\n        for i in range(self.num_layers):\n            layer_inp_dim = self.inp_dim if i == 0 else (self.hid_dim if self.dirs==1 else 2*self.hid_dim)\n            self.layers.append(HyperbolicGRULayer(layer_inp_dim, self.hid_dim, self.manifold, self.dirs))\n\n    def forward(self,seq,lengths):\n        inp = seq\n\n        for idx,layer in enumerate(self.layers):\n            # print(\"input to layer \",idx,\" : inp:\",inp.shape,\" , hid: \",hid.shape)\n            inp,hid = layer(inp,lengths)\n\n        return hid\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:50:50.667944Z","iopub.execute_input":"2025-04-14T18:50:50.668587Z","iopub.status.idle":"2025-04-14T18:52:02.981023Z","shell.execute_reply.started":"2025-04-14T18:50:50.668564Z","shell.execute_reply":"2025-04-14T18:52:02.980337Z"},"papermill":{"duration":75.292901,"end_time":"2025-04-14T04:11:20.696060","exception":false,"start_time":"2025-04-14T04:10:05.403159","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting git+https://github.com/geoopt/geoopt.git\n  Cloning https://github.com/geoopt/geoopt.git to /tmp/pip-req-build-wygbs_d5\n  Running command git clone --filter=blob:none --quiet https://github.com/geoopt/geoopt.git /tmp/pip-req-build-wygbs_d5\n  Resolved https://github.com/geoopt/geoopt.git to commit eaadc68fcae361778edf078b503ed79e4497c071\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from geoopt==0.5.1) (2.5.1+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from geoopt==0.5.1) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from geoopt==0.5.1) (1.15.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->geoopt==0.5.1)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.1->geoopt==0.5.1)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.1->geoopt==0.5.1)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.1->geoopt==0.5.1)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.1->geoopt==0.5.1)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.1->geoopt==0.5.1)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.1->geoopt==0.5.1)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->geoopt==0.5.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.1->geoopt==0.5.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->geoopt==0.5.1) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->geoopt==0.5.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->geoopt==0.5.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->geoopt==0.5.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->geoopt==0.5.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->geoopt==0.5.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->geoopt==0.5.1) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: geoopt\n  Building wheel for geoopt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for geoopt: filename=geoopt-0.5.1-py3-none-any.whl size=90072 sha256=e134c3daf3a1787e90700d0f753ae4a48dd32e2b87512afefae4c211787ccad0\n  Stored in directory: /tmp/pip-ephem-wheel-cache-qhp4_l4d/wheels/73/38/55/c6be8a0cd7691d5eb31c63a5452480e4725b74e228929a5593\nSuccessfully built geoopt\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, geoopt\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed geoopt-0.5.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"id":"7a1936c1","cell_type":"code","source":"class HyLinear(nn.Module):\n    def __init__(self,input_dim,output_dim,act,manifold,bias=None):\n        super(HyLinear, self).__init__()\n        self.inp_dim = input_dim\n        self.out_dim = output_dim\n        self.manifold = manifold\n        self.activation = act\n        self.weight_matrix = nn.Parameter(torch.randn((self.out_dim,self.inp_dim),dtype = torch.float64))\n        if(bias is not None):\n            self.bias = geoopt.tensor.ManifoldParameter(self.manifold.projx(self.manifold.expmap0(torch.zeros(self.out_dim,dtype=torch.float64))),manifold=self.manifold)\n        else:\n            self.bias=None\n\n    def reset_parameters(self):\n        torch.nn.init.xavier_uniform_(self.weight_matrix, gain=math.sqrt(2))\n        if(self.bias is not None):\n            torch.nn.init.constant_(self.bias, 0)\n\n\n    def forward(self,x):\n        # x = x.double()\n        op = self.manifold.mobius_matvec(self.weight_matrix,x)\n        op = self.manifold.projx(op)\n        if(self.bias is not None):\n            op = self.manifold.mobius_add(op,self.bias)\n            op = self.manifold.projx(op)\n        if(self.activation is not None):\n            op = self.manifold.projx(self.manifold.expmap0(self.activation(self.manifold.logmap0(op))))\n        return op","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:52:08.222150Z","iopub.execute_input":"2025-04-14T18:52:08.222867Z","iopub.status.idle":"2025-04-14T18:52:08.231384Z","shell.execute_reply.started":"2025-04-14T18:52:08.222834Z","shell.execute_reply":"2025-04-14T18:52:08.230813Z"},"papermill":{"duration":0.04644,"end_time":"2025-04-14T04:11:20.772166","exception":false,"start_time":"2025-04-14T04:11:20.725726","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"042ae37d","cell_type":"code","source":"import random\nimport torch_geometric\nfrom torch_geometric.data import Batch, Data\n\nclass ContextLSTM(nn.Module):\n  def __init__(self,embed_model, embedding_dim, hidden_size_message, gat_dim, num_classes,  manifold, num_layers, dirs,context_win_graph=5):\n    super(ContextLSTM,self).__init__()\n    seed = 100\n    self.context_win_graph=context_win_graph\n    torch.manual_seed(seed)\n    random.seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\n    self.embedding_model = embed_model\n    self.embedding_size = embedding_dim\n\n    self.manifold = manifold\n    self.num_layers = num_layers\n    self.dirs = dirs\n    \n    for param in self.embedding_model.parameters():\n                param.requires_grad = False # hyperparameter\n\n   \n    # can add hylinear here\n    self.gru_message =  HyperbolicGRU(embedding_dim,hidden_size,self.manifold,self.num_layers,self.dirs)\n      \n    # self.gat1 = torch_geometric.nn.conv.GATConv(in_channels=hidden_size_message*2,out_channels=gat_dim//2,heads=4)\n    self.gat1 = torch_geometric.nn.conv.GATConv(in_channels=hidden_size_message*2,out_channels=gat_dim*2,heads=4,  concat=False).to(torch.float64)\n      \n    self.gat2 = torch_geometric.nn.conv.GATConv(in_channels=gat_dim*2,out_channels=gat_dim,heads=2 , concat=False).to(torch.float64)\n    self.relu = torch.nn.ReLU()\n    self.tanh = torch.nn.Tanh()\n    self.sigmoid = torch.nn.Sigmoid()  \n    self.gate1 = nn.Linear(hidden_size_message * 2 + gat_dim,hidden_size_message * 2,dtype=torch.float64)\n    self.gate2 = nn.Linear(hidden_size_message * 2 + gat_dim,gat_dim,dtype=torch.float64)\n    self.hidden_size_message = hidden_size_message\n    self.gat_dim = gat_dim\n\n\n    self.attn_dim = 256  # Should match your hidden size requirements\n    self.attn = nn.MultiheadAttention(\n        embed_dim=self.attn_dim, \n        num_heads=8,\n        kdim=self.hidden_size_message*2 + self.gat_dim,\n        vdim=self.hidden_size_message*2 + self.gat_dim,\n        dtype=torch.float64\n    )\n    self.fusion_proj = nn.Linear(self.hidden_size_message*2 + self.gat_dim, self.attn_dim,dtype=torch.float64)\n\n    self.fc = nn.Linear(hidden_size_message * 2 + gat_dim+1, num_classes).to(dtype=torch.float64)\n\n    # self.fc = nn.Linear(self.attn_dim, num_classes,dtype=torch.float64)\n\n  def attn_fusion(self, x):\n      # Project combined features\n    projected = self.fusion_proj(x)  # [batch, attn_dim]\n    \n    # Attention expects [seq_len, batch, features]\n    projected = projected.unsqueeze(0)  # [1, batch, attn_dim]\n    \n    # Self-attention with learned relationships\n    attn_output, _ = self.attn(\n        projected,  # Query\n        x.unsqueeze(0),  # Key (original features)\n        x.unsqueeze(0)   # Value (original features)\n    )\n    \n    return attn_output.squeeze(0)\n      \n  def fusion(self,x):\n      lstm_emb = x[:,:2*self.hidden_size_message]\n      gat_emb = x[:,2*self.hidden_size_message:]\n      \n      lstm_emb_tanh = self.tanh(lstm_emb) \n      gat_emb_tanh = self.tanh(gat_emb)\n      # print('lstm emb: ',lstm_emb.shape)\n      # print(\"gat emb shape: \",gat_emb.shape)\n      mixed = torch.cat((lstm_emb,gat_emb),dim=1)\n      mixed_sigmoid_left = self.sigmoid(self.gate1(mixed))\n      mixed_sigmoid_right = self.sigmoid(self.gate2(mixed))\n\n      final_emb = torch.cat((mixed_sigmoid_left*lstm_emb_tanh,mixed_sigmoid_right*gat_emb_tanh),dim=1)\n      return final_emb\n\n  def get_message_emb(self,input_ids,lengths):\n    embedded = self.manifold.expmap0(self.embedding_model(input_ids).last_hidden_state)\n    last_hidden = self.gru_message(embedded,lengths)\n    return last_hidden\n\n  \n\n  def forward(self, input_ids, num_messages, lengths , scores):\n    total_messages = sum(num_messages)\n    # print(input_ids.shape)\n    inputs_to_msg_encoder = input_ids\n    encoded_messages = self.manifold.logmap0(self.get_message_emb(inputs_to_msg_encoder,lengths))\n    input_to_convo_encoder = torch.split(encoded_messages,num_messages)\n    # print(input_to_convo_encoder[0].shape)\n\n    tot_data = []\n\n    # for i in range(len(input_to_convo_encoder)):\n    #     msg_embs = input_to_convo_encoder[i] # num_msgs x emb_dim\n    #     n_nodes = msg_embs.shape[0]\n    #     edge_ind = torch.combinations(torch.arange(n_nodes), r=2).T\n    #     edge_ind = torch.cat([edge_ind, edge_ind.flip(0)], dim=1).to(input_ids.device)\n    \n    #     tot_data.append(Data(x=msg_embs,edge_index=edge_ind))\n\n\n    threshold = 0.7  # Can tune this\n    \n    for i, msg_embs in enumerate(input_to_convo_encoder):\n        n_nodes = msg_embs.shape[0]\n        sources, targets = [], []\n    \n        norm_embs = torch.nn.functional.normalize(msg_embs, p=2, dim=1)\n    \n        sim_matrix = torch.mm(norm_embs, norm_embs.T)  \n    \n        for src in range(n_nodes):\n            for tgt in range(n_nodes):\n                if src > tgt and sim_matrix[src, tgt] > threshold:\n                    # print(src,tgt)\n                    sources.append(src)\n                    targets.append(tgt)\n    \n    \n        edge_index = torch.tensor([sources, targets], device=input_ids.device, dtype=torch.long)\n    \n        tot_data.append(Data(x=msg_embs, edge_index=edge_index))\n\n    tot_data = Batch.from_data_list(tot_data)\n    # print(\"tot_data dtype: \",tot_data.x.dtype)\n    from_gat1 = self.relu(self.gat1(tot_data.x,tot_data.edge_index))\n    \n    # print(\"from gat 1 shape: \",from_gat1.shape)\n\n    from_gat2 = self.gat2(from_gat1,tot_data.edge_index)\n    # print(\"enc msg shape: \",encoded_messages.shape)\n    # print(\"from_gat2 shap: \",from_gat2.shape)\n      \n    input_for_fusion = [] \n    prev = 0\n    # print(\"enc msg shape: \",encoded_messages.shape)\n    for i, msg_emb in enumerate(encoded_messages):\n        # print(\"i: \",i)\n        inp = torch.cat((msg_emb,from_gat2[i]),dim=0)\n        input_for_fusion.append(inp)\n    # print(\"shape before fusion: \",torch.stack(input_for_fusion).shape)\n    # final_combined = self.fusion(torch.stack(input_for_fusion))\n    # print(\"final combined shape: \",final_combined.shape)\n    final_input = torch.cat((torch.stack(input_for_fusion),  scores.unsqueeze(1)), dim=1)\n    # print(final_input.shape)\n    # logits = self.fc(torch.stack(input_for_fusion))\n    logits = self.fc(((final_input)))\n      \n    # print(\"logits shape: \",logits.shape)\n    return logits\n\n","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:54:08.183194Z","iopub.execute_input":"2025-04-14T18:54:08.183892Z","iopub.status.idle":"2025-04-14T18:54:08.199753Z","shell.execute_reply.started":"2025-04-14T18:54:08.183867Z","shell.execute_reply":"2025-04-14T18:54:08.198895Z"},"id":"hG6f4m63ND-N","papermill":{"duration":7.151156,"end_time":"2025-04-14T04:11:27.956913","exception":false,"start_time":"2025-04-14T04:11:20.805757","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":17},{"id":"d328b29e","cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()\ntorch.cuda.ipc_collect()","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:54:11.608076Z","iopub.execute_input":"2025-04-14T18:54:11.608892Z","iopub.status.idle":"2025-04-14T18:54:12.329912Z","shell.execute_reply.started":"2025-04-14T18:54:11.608858Z","shell.execute_reply":"2025-04-14T18:54:12.329097Z"},"papermill":{"duration":0.269032,"end_time":"2025-04-14T04:11:28.249063","exception":false,"start_time":"2025-04-14T04:11:27.980031","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":18},{"id":"8447d633","cell_type":"code","source":"from transformers import BertModel\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nembedding_dim = 768\nhidden_size = 128\nnum_classes = 2\ngat_dim = 50\n\nseed = 100\n\ntorch.manual_seed(seed)\nrandom.seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\nmanifold = geoopt.manifolds.PoincareBall(c=1.0)\n\nmodel_embed = BertModel.from_pretrained('bert-base-uncased').to(device)\n\nmodel = ContextLSTM(model_embed,  embedding_dim, hidden_size,gat_dim, num_classes,manifold , 1,2,5)\nmodel = model.to(device)\n\nclass_weights = torch.tensor([1.0 / 0.10, 1.0 / 0.90], dtype=torch.float64)\nclass_weights = class_weights.to(device)\n\n\n# model = ContextLSTM(vocab, glove_file, embedding_dim, hidden_size//2,hidden_size, num_classes)\n# model = model.to(device)\noptimizer =  geoopt.optim.RiemannianAdam(model.parameters(),lr=1e-3)\nloss = nn.CrossEntropyLoss(weight=class_weights)\n\ntrain_dataset = Deception_dataset_context(train)\nval_dataset = Deception_dataset_context(val)\ntrain_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=collate_fn_context)\nval_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_context)\n\n\ntest_dataset = Deception_dataset_context(test)\ntest_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn_context)\n\nprint(\"hey\")\nfor epoch in range(15):\n    \n    model.train()\n    train_loss = 0\n    train_preds, train_labels = [], []\n    for batch in tqdm(train_dataloader):\n        messages = batch[\"messages\"].to(device)\n        lengths = batch[\"lengths\"]\n        labels = batch[\"labels\"].to(device)\n        num_messages = batch['num_messages']\n        scores = batch['deltas'].to(device)\n\n        optimizer.zero_grad()\n        logits = model(messages, num_messages,lengths,scores)\n        loss_ = loss(logits, labels)\n        loss_.backward()\n        optimizer.step()\n\n        train_loss += loss_.item()\n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        train_preds.extend(preds)\n        train_labels.extend(labels.cpu().numpy())\n\n\n    train_loss /= len(train_dataloader)\n    train_f1 = f1_score(train_labels, train_preds, average='macro')\n\n\n    model.eval()\n    val_loss = 0\n    val_preds, val_labels = [], []\n    with torch.no_grad():\n        for batch in val_dataloader:\n            messages = batch[\"messages\"].to(device)\n            lengths = batch[\"lengths\"]\n            labels = batch[\"labels\"].to(device)\n            num_messages = batch['num_messages']\n            scores = batch['deltas'].to(device)\n            logits = model(messages, num_messages,lengths,scores)\n            loss_ = loss(logits, labels)\n            val_loss += loss_.item()\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            val_preds.extend(preds)\n            val_labels.extend(labels.cpu().numpy())\n\n    val_loss /= len(val_dataloader)\n    val_f1 = f1_score(val_labels, val_preds, average='macro')\n\n    model.eval()\n    test_preds, test_labels = [], []\n    with torch.no_grad():\n        for batch in test_dataloader:\n            messages = batch[\"messages\"].to(device)\n            lengths = batch[\"lengths\"]\n            labels = batch[\"labels\"].to(device)\n            num_messages = batch['num_messages']\n            scores = batch['deltas'].to(device)\n            logits = model(messages, num_messages,lengths,scores)\n    \n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            test_preds.extend(preds)\n            test_labels.extend(labels.cpu().numpy())\n    \n    \n    test_f1 = f1_score(test_labels, test_preds, average='macro')\n\n    torch.save(model.state_dict(),f\"epoch_{epoch+1}.pth\")\n    print(test_f1)\n\n\n    print(f\"Epoch {epoch+1}:  Train Loss: {train_loss:.4f}, Train F1: {train_f1:.4f} Val Loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:54:16.212941Z","iopub.execute_input":"2025-04-14T18:54:16.213226Z","execution_failed":"2025-04-14T19:16:56.704Z"},"id":"M7eDWYJtgSpg","outputId":"bac03c34-5da2-4c9e-fb8c-da347295e309","papermill":{"duration":18615.868995,"end_time":"2025-04-14T09:21:44.140863","exception":false,"start_time":"2025-04-14T04:11:28.271868","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"hey\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 199/199 [19:28<00:00,  5.87s/it]\n","output_type":"stream"},{"name":"stdout","text":"0.48692930888245445\nEpoch 1:  Train Loss: 0.5925, Train F1: 0.4899 Val Loss: 0.5789, Val F1: 0.4888\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/199 [00:10<17:16,  5.26s/it]","output_type":"stream"}],"execution_count":null},{"id":"5894a296","cell_type":"code","source":" # torch.save(model.state_dict(),f\"gat+lstm+glove_best.pth\")","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:48:56.764894Z","iopub.status.idle":"2025-04-14T18:48:56.765214Z","shell.execute_reply.started":"2025-04-14T18:48:56.765044Z","shell.execute_reply":"2025-04-14T18:48:56.765056Z"},"papermill":{"duration":0.14756,"end_time":"2025-04-14T09:21:44.430250","exception":false,"start_time":"2025-04-14T09:21:44.282690","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"ef6a8f71","cell_type":"code","source":"# test_dataset = Deception_dataset_context(test, vocab)\n# test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_context)\n\n\n# model.eval()\n# test_preds, test_labels = [], []\n# with torch.no_grad():\n#     for batch in test_dataloader:\n#         messages = batch[\"messages\"].to(device)\n#         lengths = batch[\"lengths\"]\n#         labels = batch[\"labels\"].to(device)\n#         num_messages = batch['num_messages']\n#         scores = batch['deltas'].to(device)\n#         logits = model(messages, num_messages,lengths,scores)\n\n#         preds = torch.argmax(logits, dim=1).cpu().numpy()\n#         test_preds.extend(preds)\n#         test_labels.extend(labels.cpu().numpy())\n\n\n# test_f1 = f1_score(test_labels, test_preds, average='macro')\n\n# print(test_f1)","metadata":{"execution":{"iopub.status.busy":"2025-04-14T18:48:56.766110Z","iopub.status.idle":"2025-04-14T18:48:56.766453Z","shell.execute_reply.started":"2025-04-14T18:48:56.766262Z","shell.execute_reply":"2025-04-14T18:48:56.766277Z"},"id":"bzlomltYh7zj","outputId":"6e04ba6a-66f7-4bad-edd5-d0f72f7e33fb","papermill":{"duration":0.146124,"end_time":"2025-04-14T09:21:44.717694","exception":false,"start_time":"2025-04-14T09:21:44.571570","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"25e19da1","cell_type":"code","source":"","metadata":{"id":"vbqfSpqHa4fa","papermill":{"duration":0.141919,"end_time":"2025-04-14T09:21:45.000362","exception":false,"start_time":"2025-04-14T09:21:44.858443","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}